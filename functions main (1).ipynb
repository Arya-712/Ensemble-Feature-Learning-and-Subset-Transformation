{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b837bd13",
   "metadata": {},
   "source": [
    "### Fisher score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e0aaef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fisher_score(X, y):\n",
    "    \"\"\"\n",
    "    Fisher Score for each feature.\n",
    "        X: Feature matrix (N samples x M features)\n",
    "        y: Labels (N samples)\n",
    "    Returns:\n",
    "        scores: Fisher Scores for all features (array of length M)\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    unique_classes = np.unique(y)\n",
    "    scores = np.zeros(n_features)\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        overall_mean = np.mean(X[:, i])  # Mean of the feature across all samples\n",
    "        between_class_var = 0\n",
    "        within_class_var = 0\n",
    "        \n",
    "        for cls in unique_classes:\n",
    "            class_indices = np.where(y == cls)[0]\n",
    "            class_data = X[class_indices, i]\n",
    "            class_mean = np.mean(class_data)\n",
    "            class_var = np.var(class_data)\n",
    "            \n",
    "            between_class_var += len(class_data) * (class_mean - overall_mean) ** 2\n",
    "            within_class_var += len(class_data) * class_var\n",
    "            \n",
    "        # Calculate Fisher Score for the feature\n",
    "        scores[i] = between_class_var / (within_class_var + 1e-6)  # Avoid division by zero\n",
    "    \n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f7543",
   "metadata": {},
   "source": [
    "### ReliefF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "128df7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def reliefF(X, y, k=10):\n",
    "    \"\"\"\n",
    "    ReliefF feature ranking.\n",
    "    Args:\n",
    "        X: Feature matrix (N samples x M features)\n",
    "        y: Labels (N samples)\n",
    "        k: Number of nearest neighbors (default is 10)\n",
    "    Returns:\n",
    "        scores: Feature importance scores (higher is better)\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    scores = np.zeros(n_features)\n",
    "    \n",
    "    nn = NearestNeighbors(n_neighbors=k+1)  # +1 to exclude the sample itself\n",
    "    nn.fit(X)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Find the k nearest neighbors (including the sample itself)\n",
    "        distances, indices = nn.kneighbors([X[i]])\n",
    "        \n",
    "        # Exclude the sample itself (1st index is the sample itself)\n",
    "        indices = indices[0][1:]\n",
    "        \n",
    "        # Find nearest hits and nearest misses\n",
    "        near_hits = indices[y[indices] == y[i]]\n",
    "        near_misses = indices[y[indices] != y[i]]\n",
    "        \n",
    "        # Update scores for each feature\n",
    "        for feature in range(n_features):\n",
    "            hit_diff = np.sum((X[i, feature] - X[near_hits, feature]) ** 2)\n",
    "            miss_diff = np.sum((X[i, feature] - X[near_misses, feature]) ** 2)\n",
    "            scores[feature] += hit_diff - miss_diff\n",
    "\n",
    "    # Normalize scores by the number of samples\n",
    "    scores /= n_samples\n",
    "    \n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f498c313",
   "metadata": {},
   "source": [
    "### Robust multi-label feature selection with dual-graph regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2440f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drmfs(X, Y, lambda1=0.1, lambda2=0.1, lambda3=0.1):\n",
    "    N, M = X.shape\n",
    "    N, L = Y.shape\n",
    "    dist_X = pairwise_distances(X, metric='cosine')\n",
    "    dist_Y = pairwise_distances(Y, metric='jaccard')\n",
    "    L_X = np.exp(-dist_X**2 / (2 * 1.0 ** 2))\n",
    "    np.fill_diagonal(L_X, 0)\n",
    "    L_Y = np.exp(-dist_Y**2 / (2 * 1.0 ** 2))\n",
    "    np.fill_diagonal(L_Y, 0)\n",
    "    W = cp.Variable((M, L))\n",
    "    data_fitting = cp.norm(Y - X @ W, 'fro')**2\n",
    "    feature_sparsity = lambda1 * cp.norm(W, 'fro')**2\n",
    "    feature_graph = lambda2 * cp.trace(W.T @ L_X @ W)\n",
    "    label_graph = lambda3 * cp.trace(W.T @ L_Y @ W)\n",
    "    objective = cp.Minimize(data_fitting + feature_sparsity + feature_graph + label_graph)\n",
    "    problem = cp.Problem(objective)\n",
    "    problem.solve()\n",
    "    return W.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c0be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vikor(decision_matrix, weights, v=0.5):\n",
    "    # Step 1: Identify f* and f-\n",
    "    f_star = np.max(decision_matrix, axis=0)\n",
    "    f_minus = np.min(decision_matrix, axis=0)\n",
    "    \n",
    "    # Step 2: Compute S and R\n",
    "    S = np.zeros(decision_matrix.shape[0])\n",
    "    R = np.zeros(decision_matrix.shape[0])\n",
    "    for i in range(decision_matrix.shape[0]):\n",
    "        normalized_diff = weights * (f_star - decision_matrix[i]) / (f_star - f_minus)\n",
    "        S[i] = np.sum(normalized_diff)\n",
    "        R[i] = np.max(normalized_diff)\n",
    "    \n",
    "    # Step 3: Compute Q\n",
    "    S_star, S_minus = np.min(S), np.max(S)\n",
    "    R_star, R_minus = np.min(R), np.max(R)\n",
    "    Q = np.zeros(decision_matrix.shape[0])\n",
    "    for i in range(decision_matrix.shape[0]):\n",
    "        Q[i] = v * (S[i] - S_star) / (S_minus - S_star) + (1 - v) * (R[i] - R_star) / (R_minus - R_star)\n",
    "    \n",
    "    # Step 4: Rank features\n",
    "    rankings = np.argsort(Q)  # Ascending order\n",
    "    return Q, rankings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61fa6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def topsis(decision_matrix, weights):\n",
    "    \"\"\"\n",
    "    Implements TOPSIS for ranking features.\n",
    "    Args:\n",
    "        decision_matrix: 2D array (features x criteria).\n",
    "        weights: 1D array of criteria weights (must sum to 1).\n",
    "    Returns:\n",
    "        closeness: Array of relative closeness scores (C_i).\n",
    "        rankings: Array of feature indices sorted by rank (descending).\n",
    "    \"\"\"\n",
    "    # Step 1: Normalize the decision matrix\n",
    "    norm_matrix = decision_matrix / np.sqrt((decision_matrix ** 2).sum(axis=0))\n",
    "    \n",
    "    # Step 2: Apply weights\n",
    "    weighted_matrix = norm_matrix * weights\n",
    "    \n",
    "    # Step 3: Determine ideal and negative-ideal solutions\n",
    "    ideal_solution = np.max(weighted_matrix, axis=0)\n",
    "    negative_ideal_solution = np.min(weighted_matrix, axis=0)\n",
    "    \n",
    "    # Step 4: Compute distances\n",
    "    distance_to_ideal = np.sqrt(((weighted_matrix - ideal_solution) ** 2).sum(axis=1))\n",
    "    distance_to_negative_ideal = np.sqrt(((weighted_matrix - negative_ideal_solution) ** 2).sum(axis=1))\n",
    "    \n",
    "    # Step 5: Calculate relative closeness\n",
    "    closeness = distance_to_negative_ideal / (distance_to_ideal + distance_to_negative_ideal)\n",
    "    \n",
    "    # Step 6: Rank features\n",
    "    rankings = np.argsort(closeness)[::-1]\n",
    "    \n",
    "    return closeness, rankings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "114684a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def codas(decision_matrix, weights, alpha=0.5):\n",
    "    # Step 1: Normalize the decision matrix\n",
    "    norm_decision_matrix = decision_matrix / np.sqrt(np.sum(decision_matrix**2, axis=0))\n",
    "\n",
    "    # Step 2: Calculate the weighted normalized decision matrix\n",
    "    weighted_matrix = norm_decision_matrix * weights\n",
    "\n",
    "    # Step 3: Calculate the negative ideal solution\n",
    "    negative_ideal_solution = np.min(weighted_matrix, axis=0)\n",
    "\n",
    "    # Step 4: Calculate Euclidean and Taxicab distances\n",
    "    euclidean_distances = np.sqrt(np.sum((weighted_matrix - negative_ideal_solution)**2, axis=1))\n",
    "    taxicab_distances = np.sum(np.abs(weighted_matrix - negative_ideal_solution), axis=1)\n",
    "\n",
    "    # Step 5: Calculate the assessment scores\n",
    "    assessment_scores = euclidean_distances + alpha * taxicab_distances\n",
    "\n",
    "    # Step 6: Rank the alternatives\n",
    "    rankings = np.argsort(assessment_scores)\n",
    "\n",
    "    return assessment_scores, rankings\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
